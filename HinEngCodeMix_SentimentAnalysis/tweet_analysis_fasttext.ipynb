{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fasttext embeddings.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vba7EmDCnX7A",
        "colab_type": "code",
        "outputId": "81106984-4b98-41ec-b89c-af6046db14c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "!pip install fasttext"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.6/dist-packages (0.9.1)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (41.4.0)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext) (1.17.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clTTJj-7nhBg",
        "colab_type": "code",
        "outputId": "c4cc0f46-d058-4a38-bed9-fef45d298570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "import fasttext\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/bert_dataset/assignment')\n",
        "os.getcwd()\n",
        "os.listdir()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test.txt',\n",
              " 'train.txt',\n",
              " 'myfile.txt',\n",
              " 'final.txt',\n",
              " 'ep_10.bin',\n",
              " 'ep_100.bin',\n",
              " 'train_final_trans.txt',\n",
              " 'test_final_trans.txt',\n",
              " 'new_final.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WQpbDsMoDR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "train_data = []\n",
        "ans = 0\n",
        "with open(\"train.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    tweet = {}\n",
        "    for row in f.readlines():\n",
        "        row_data = row.strip().split()\n",
        "        if len(row_data)==0 or len(row_data)==1:\n",
        "            continue\n",
        "        if row_data[0]==\"meta\":\n",
        "            train_data.append(tweet)\n",
        "            tweet = {}\n",
        "            tweet[\"id\"] = row_data[1]\n",
        "            tweet[\"class\"] = row_data[2]\n",
        "            tweet[\"text\"] = []\n",
        "            tweet[\"schema\"] = []\n",
        "        else:\n",
        "            tweet[\"text\"].append(row_data[0])\n",
        "            tweet[\"schema\"].append(row_data[1])\n",
        "train_data = train_data[1:]\n",
        "\n",
        "for i in train_data:\n",
        "    new_tok=[]\n",
        "    tokens=i['text']\n",
        "    tokens=list(filter(lambda a: a !='//' and a!='/' and a!='co' and a!='https' and a!='...' and a!='@', tokens))\n",
        "\n",
        "    x=\"\".join([\" \"+i if not i.startswith(\"'\") and i not in string.punctuation else i for i in tokens]).strip()\n",
        "    i['sentence']=x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8o1mwGcs72K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "419f3267-ee6a-4b80-a1d7-9b193eb8d4ee"
      },
      "source": [
        "test_data = []\n",
        "ans = 0\n",
        "with open(\"test.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    tweet = {}\n",
        "    for row in f.readlines():\n",
        "        row_data = row.strip().split()\n",
        "        if len(row_data)==0 or len(row_data)==1:\n",
        "            continue\n",
        "        if row_data[0]==\"meta\":\n",
        "            test_data.append(tweet)\n",
        "            tweet = {}\n",
        "            tweet[\"id\"] = row_data[1]\n",
        "            tweet[\"class\"] = row_data[2]\n",
        "            tweet[\"text\"] = []\n",
        "            tweet[\"schema\"] = []\n",
        "        else:\n",
        "            tweet[\"text\"].append(row_data[0])\n",
        "            tweet[\"schema\"].append(row_data[1])\n",
        "test_data = test_data[1:]\n",
        "\n",
        "for i in test_data:\n",
        "    new_tok=[]\n",
        "    tokens=i['text']\n",
        "    tokens=list(filter(lambda a: a !='//' and a!='/' and a!='co' and a!='https' and a!='...' and a!='@', tokens))\n",
        "\n",
        "    x=\"\".join([\" \"+i if not i.startswith(\"'\") and i not in string.punctuation else i for i in tokens]).strip()\n",
        "    i['sentence']=x\n",
        "print(len(test_data))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1868\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnh-PoR4tKKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "for i in test_data:\n",
        "    token=i['text']\n",
        "    temp_token=[]\n",
        "    j=0\n",
        "    while j<len(token):\n",
        "        if(token[j]=='@'):\n",
        "            j=j+2\n",
        "        elif(token[j]=='https'):\n",
        "            break\n",
        "        elif(token[j]=='_' or token[j]=='-' or token[j]=='#' or token[j]=='+'):\n",
        "            j=j+1\n",
        "        else:    \n",
        "            temp_token.append(token[j])\n",
        "            j=j+1\n",
        "            #print(j)\n",
        "    \n",
        "        \n",
        "    x=\"\".join([\" \"+i if not i.startswith(\"'\") and i not in string.punctuation else i for i in temp_token]).strip()\n",
        "    i['uncleaned']=x\n",
        "    k=re.sub(r\"\\.+\",\"\",x)\n",
        "    i['clean']=k.encode('ascii', 'ignore').decode('ascii')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VRo2VO6Jfas",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "for i in train_data:\n",
        "    token=i['text']\n",
        "    temp_token=[]\n",
        "    j=0\n",
        "    while j<len(token):\n",
        "        if(token[j]=='@'):\n",
        "            j=j+2\n",
        "        elif(token[j]=='https'):\n",
        "            break\n",
        "        elif(token[j]=='_' or token[j]=='-' or token[j]=='#' or token[j]=='+'):\n",
        "            j=j+1\n",
        "        else:    \n",
        "            temp_token.append(token[j])\n",
        "            j=j+1\n",
        "            #print(j)\n",
        "    \n",
        "        \n",
        "    x=\"\".join([\" \"+i if not i.startswith(\"'\") and i not in string.punctuation else i for i in temp_token]).strip()\n",
        "    i['uncleaned']=x\n",
        "    k=re.sub(r\"\\.+\",\"\",x)\n",
        "    i['clean']=k.encode('ascii', 'ignore').decode('ascii')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hiy17LgJp8M",
        "colab_type": "code",
        "outputId": "70fd3aee-eca6-4b37-9c73-de0a09100377",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "import re\n",
        "for i in train_data[:10]:\n",
        "  print(i['clean'].lower())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pakistan ka ghra tauq he pakistan israel ko tasleem nahein kerta isko palestine kehta he occupied palestine\n",
            "madarchod mulle ye mathura me nahi dikha tha jab mullo ne hindu ko iss liye mara ki vo lasse ki paise mag liye the \n",
            "manya pradhan mantri mahoday shriman narendra modi ji pradhanmantri banne par hardik badhai tahe dil \n",
            "krishna jcb full trend me chal rahi aa\n",
            "loksabha me janta sirf modi ko vote de rahi thi na ki kisi mp or bjp ko without m \n",
            "bhosdike tum pechvade ki tatti hi rahoge bc\n",
            "love u bhaijan  father son  bharat iambharat bharatthiseid best pic from entire promotions  mashallah \n",
            "tumhara pass abh deemagh hai nahi islea google ko apna deemagh banaya hua hai har koi tumhari tarh \n",
            "nolo weni ankere o gae this weekend \n",
            "aimim lage raho mullo tumhre issi quran faad gyan ki kayal hain duniya allah bhi khus \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgHcKW0JtL38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#result=full_text.encode('ascii', 'ignore').decode('ascii')\n",
        "file1 = open(\"new_final.txt\",'w',encoding='utf-8')\n",
        "write_data=[]\n",
        "\n",
        "for i in train_data:\n",
        "  write_data.append(i['clean'].lower()+str('\\n'))\n",
        "\n",
        "\n",
        "file1.writelines(write_data) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CeeOZx-oJYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import fasttext\n",
        "\n",
        "model = fasttext.train_unsupervised('new_final.txt','skipgram', minn=2, maxn=5, dim=300,epoch=150, lr=0.1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAumaIzdPz6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_model(\"ep_150.bin\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTRhJXubVI2u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1f4e4b67-288d-4b12-de33-96095bc3d591"
      },
      "source": [
        "import fasttext\n",
        "\n",
        "model = fasttext.load_model(\"ep_150.bin\")\n",
        "#model.get_word_vector('the')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIu22OXMWEwz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "2eb31852-c0c7-429c-8de6-521035788f1c"
      },
      "source": [
        "f=model.get_output_matrix()\n",
        "print(f.shape)\n",
        "p=model.words\n",
        "print(len(p))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5979, 300)\n",
            "5979\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Vx-DSFRXqxZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9df0fb5-dfc2-43df-d268-6ff2845c6bdb"
      },
      "source": [
        "embeddings={}\n",
        "all_words=model.words\n",
        "out_vec=model.get_word_vector\n",
        "\n",
        "for i in all_words:\n",
        "  embeddings[i]=out_vec(i)\n",
        "\n",
        "print(len(embeddings))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5979\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voIuHP4mZoWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab={}\n",
        "for i in range(len(all_words)):\n",
        "  vocab[all_words[i]]=i\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4LHlv2LXujC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "num_words = len(embeddings) + 1\n",
        "EMBED_DIM=300\n",
        "embedding_matrix = np.zeros((num_words, EMBED_DIM))\n",
        "for word,i in vocab.items():\n",
        "    embedding_vector = embeddings.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "embeddings_index = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ro-rTk7epI2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "facad65f-483b-46a4-bdf0-b6b20a6d314b"
      },
      "source": [
        "embedding_matrix.shape\n",
        "#print(embedding_matrix[1])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5980, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNyfjPsnaOtV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "outputId": "b109a1fe-9590-46cf-8072-7bdde62b4671"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.callbacks import TensorBoard, CSVLogger\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Flatten,LSTM,Conv1D,GlobalMaxPool1D,Dropout,Bidirectional,GRU\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras import optimizers\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.models import load_model\n",
        "from nltk.corpus import stopwords\n",
        "import operator\n",
        "import os\n",
        "import keras"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfxZ9KoDaoh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import string\n",
        "train_data = []\n",
        "ans = 0\n",
        "with open(\"train.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    tweet = {}\n",
        "    for row in f.readlines():\n",
        "        row_data = row.strip().split()\n",
        "        if len(row_data)==0 or len(row_data)==1:\n",
        "            continue\n",
        "        if row_data[0]==\"meta\":\n",
        "            train_data.append(tweet)\n",
        "            tweet = {}\n",
        "            tweet[\"id\"] = row_data[1]\n",
        "            tweet[\"class\"] = row_data[2]\n",
        "            tweet[\"text\"] = []\n",
        "            tweet[\"schema\"] = []\n",
        "        else:\n",
        "            tweet[\"text\"].append(row_data[0])\n",
        "            tweet[\"schema\"].append(row_data[1])\n",
        "train_data = train_data[1:]\n",
        "\n",
        "for i in train_data:\n",
        "    new_tok=[]\n",
        "    tokens=i['text']\n",
        "    tokens=list(filter(lambda a: a !='//' and a!='/' and a!='co' and a!='https' and a!='...' and a!='@', tokens))\n",
        "\n",
        "    x=\"\".join([\" \"+i if not i.startswith(\"'\") and i not in string.punctuation else i for i in tokens]).strip()\n",
        "    i['sentence']=x\n",
        "    \n",
        "for i in train_data:\n",
        "    token=i['text']\n",
        "    temp_token=[]\n",
        "    j=0\n",
        "    while j<len(token):\n",
        "        if(token[j]=='@'):\n",
        "            j=j+2\n",
        "        elif(token[j]=='https'):\n",
        "            break\n",
        "        elif(token[j]=='_' or token[j]=='-' or token[j]=='#' or token[j]=='+'):\n",
        "            j=j+1\n",
        "        else:    \n",
        "            temp_token.append(token[j])\n",
        "            j=j+1\n",
        "            #print(j)\n",
        "    \n",
        "        \n",
        "    x=\"\".join([\" \"+i if not i.startswith(\"'\") and i not in string.punctuation else i for i in temp_token]).strip()\n",
        "    i['uncleaned']=x\n",
        "    k=re.sub(r\"\\.+\",\"\",x)\n",
        "    i['clean']=k.encode('ascii', 'ignore').decode('ascii')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aU6rY9whr5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in train_data:\n",
        "  if(i['class']=='negative'):\n",
        "    i['label']=0\n",
        "  elif(i['class']=='positive'):\n",
        "    i['label']=1\n",
        "  else:\n",
        "    i['label']=2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JesQ-FylbThG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_statement(statement):\n",
        "    #statement = [w for w in statement.split(' ') if w not in stopwords.words('english')]\n",
        "    #statement = ' '.join(statement)\n",
        "    text = text_to_word_sequence(statement)\n",
        "    val = [0] * 30\n",
        "    val = [vocab[t] for t in text if t in vocab] \n",
        "    return val\n",
        "\n",
        "#x_train=np.zeros(shape=(len(train_data),30))\n",
        "train_lst=[]\n",
        "for i in train_data:\n",
        "  train_lst.append(preprocess_statement(i['clean']))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eA77ge9RhRY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequences = np.array(sequence.pad_sequences(train_lst,   \n",
        "                          maxlen=30, padding='post'))\n",
        "\n",
        "\n",
        "y_train=np.zeros(shape=(len(train_data),1))\n",
        "\n",
        "for i in range(len(train_data)):\n",
        "  y_train[i]=train_data[i]['label']\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep_hLfnBjSP2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "42269a92-92c6-46dc-de18-d53cdf33f96d"
      },
      "source": [
        "vocab_length = len(vocab.keys())\n",
        "hidden_size = EMBED_DIM \n",
        "lstm_size = 300\n",
        "num_steps = 30\n",
        "num_epochs = 30\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "\n",
        "model_lstm = Sequential()\n",
        "model_lstm.add(Embedding(vocab_length+1, EMBED_DIM,weights=[embedding_matrix],input_length=num_steps,trainable=False))\n",
        "model_lstm.add(Bidirectional(LSTM(hidden_size,dropout=0.2, activation='relu')))\n",
        "model_lstm.add(Dense(3, activation='softmax'))\n",
        "\n",
        "\n",
        "#statement_input = Input(shape=(num_steps,), dtype='int32', name='main_input')\n",
        "#x = Embedding(vocab_length+1,EMBED_DIM,weights=[embedding_matrix],input_length=num_steps,trainable=True)(statement_input) \n",
        "#lstm_in = Bidirectional(LSTM(lstm_size,dropout=0.2,return_sequences=True, activation='relu'))(x)\n",
        "#lstm_in = Bidirectional(LSTM(500,dropout=0.2,activation='relu'))(lstm_in)\n",
        "#dense=Dense(3, activation='softmax', name='main_output')(lstm_in)\n",
        "\n",
        "#model_lstm = Model(inputs=[statement_input], outputs=[dense])\n",
        "model_lstm.summary()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_14 (Embedding)     (None, 30, 300)           1794000   \n",
            "_________________________________________________________________\n",
            "bidirectional_14 (Bidirectio (None, 600)               1442400   \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 3)                 1803      \n",
            "=================================================================\n",
            "Total params: 3,238,203\n",
            "Trainable params: 1,444,203\n",
            "Non-trainable params: 1,794,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVV-zX1snk1f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "c94a0c53-8161-4220-a5a2-6a8c3ed2a09d"
      },
      "source": [
        "name='bhai'\n",
        "sgd = optimizers.SGD(lr=0.025, clipvalue=0.3, nesterov=True)\n",
        "adam = optimizers.Adam(lr=0.0075, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "model_lstm.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "#tb = TensorBoard()\n",
        "#csv_logger = keras.callbacks.CSVLogger('training_lstm_6.log')\n",
        "filepath= name+\"_weights_best.hdf5\"\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_categorical_accuracy',verbose=1, save_best_only=True, mode='max')\n",
        "    \n",
        "model_lstm.fit(input_sequences, y_train,\n",
        "          batch_size=32,\n",
        "          epochs=30,\n",
        "          verbose=1,\n",
        "          validation_data=(input_sequences_test, y_test))"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15130 samples, validate on 1868 samples\n",
            "Epoch 1/30\n",
            "15130/15130 [==============================] - 79s 5ms/step - loss: 0.9622 - acc: 0.5694 - val_loss: 0.9565 - val_acc: 0.5589\n",
            "Epoch 2/30\n",
            "  800/15130 [>.............................] - ETA: 1:00 - loss: 1.1157 - acc: 0.6138"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-230f44057e86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m           validation_data=(input_sequences_test, y_test))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIvVpkMPIAu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in test_data:\n",
        "  if(i['class']=='negative'):\n",
        "    i['label']=0\n",
        "  elif(i['class']=='positive'):\n",
        "    i['label']=1\n",
        "  else:\n",
        "    i['label']=2\n",
        "\n",
        "test_lst=[]\n",
        "for i in test_data:\n",
        "  test_lst.append(preprocess_statement(i['clean']))\n",
        "\n",
        "input_sequences_test = np.array(sequence.pad_sequences(test_lst,   \n",
        "                          maxlen=30, padding='post'))\n",
        "\n",
        "\n",
        "y_test_n=np.zeros(shape=(len(test_data),1))\n",
        "\n",
        "for i in range(len(test_data)):\n",
        "  y_test_n[i]=test_data[i]['label']\n",
        "\n",
        "y_test = keras.utils.to_categorical(y_test_n, num_classes=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpPOQ5N9O53A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model_lstm.evaluate(input_sequences_test, y_test, verbose=0)\n",
        "score\n",
        "pred=model_lstm.predict(input_sequences_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuTGjQgIRX_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predc=np.argmax(pred, axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrQMn4kaPHfp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "b418591a-523d-4a3b-eb4d-14e41acbb4c9"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test_n,predc))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.61      0.61      0.61       532\n",
            "         1.0       0.62      0.56      0.59       582\n",
            "         2.0       0.55      0.59      0.57       754\n",
            "\n",
            "    accuracy                           0.59      1868\n",
            "   macro avg       0.59      0.59      0.59      1868\n",
            "weighted avg       0.59      0.59      0.59      1868\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}